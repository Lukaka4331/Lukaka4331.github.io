{"pages":[],"posts":[{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2020/05/09/hello-world/"},{"title":"[Milk_Data_Process]","text":"台灣牧場乳量預測tags: Aidea_比賽Data_description 檢測報告(檔案名稱：report.csv) 分娩資料(檔案名稱：birth.csv) 配種紀錄(檔案名稱：breed.csv) 健康狀況(spec.csv) 上傳範例檔案(submission.csv) Data_processing 合併資料(concat) ==新增2019年7~10月資料== 分別讀入 第一筆釋出的資料 1df_report_1 = pd.read_csv('/content/drive/My Drive/ AIDEA_Milk_prediction/first_data/report.csv') 第二筆釋出的資料-(2019年7~10月資料) 1df_report_2 = pd.read_csv('/content/drive/My Drive/ AIDEA_Milk_prediction/second_data/report.csv') 合併資料(concat) 1df_report = pd.concat([df_report_1,df_report_2]) 2019年為預測的年度train、test的依據 1train=df_report[df_report['2']!=2019] 1test=df_report[df_report['2']==2019] 分別輸出train、test檔，以此作為之後資料處理的資料 1train.to_csv('train.csv', index=False) 1test.to_csv('test.csv', index=False) Data_Feature_Engine","link":"/2020/05/09/Milk-Data-Process/"},{"title":"資料標籤處理(Tag_Process)","text":"使用套件12345import requestsfrom bs4 import BeautifulSoupimport pandas as pdimport refrom tqdm.notebook import tqdm tag替換字元1234list_text = ['#網美必拍#夏天戲水#單車漫遊#逛老街']NEW_String = list(map(lambda list_text: list_text.replace('#網美必拍','#打卡熱點'), list_text))print(list_text)print(NEW_String) :::info input:[‘#網美必拍#夏天戲水#單車漫遊#逛老街’] output:[‘#打卡熱點#夏天戲水#單車漫遊#逛老街’]::: 判斷功能12345data_2020_ok=[data_tag[4]]print(data_2020_ok)print('#網美必拍' in data_2020_ok[0])x = \"hello world\"print('hello' in x) :::info output_1 : [‘#網美必拍#夏天戲水#單車漫遊#逛老街’] output_2 : True output_3 : True ::: 替換字元+判斷功能12345678910111213141516data_try={}data_try['try_tag']=[]data_2020_ok=[data_tag[4]]#判斷字串中有無在陣列裡if '#網美必拍' in data_2020_ok[0] or '#文青必訪' in data_2020_ok[0]:#如果有，進行替換自元的處理 print('have') data_process_1 = list(map(lambda data_2020_ok: data_2020_ok.replace('#網美必拍','#打卡熱點'), data_2020_ok)) data_try['try_tag'].extend(data_process_1) print(data_try['try_tag']) else :#如果沒有，輸出原陣列 print('not have') print(data_2020_ok) :::info條件成立: output_1 : have output_2 : [‘#打卡熱點#夏天戲水#單車漫遊#逛老街’]:::不需要的tag 台灣燈會生態體驗部落旅遊戰地文化鐵道旅遊","link":"/2020/05/10/tag-process/"},{"title":"folium","text":"title: foliumdate: 2020-05-11 13:03:39tags:python toc: true categories: [python, folium] –# Folium_Tutorial tags: Data_visualization海洋廢棄物預測地圖視覺化 匯入資料 123import foliumimport pandas as pddf_train = pd.read_csv('train.csv') 地圖設置 1m_1 = folium.Map([23.5, 121], zoom_start=7,tiles='OpenStreetMap') 標記所有集群(MarkerCluster)聚類處理 如果每個狀態有300個標記怎麼辦呢？它看起來就會很亂。 為此，我們必須聚集所有標記，當我們放大地圖時，集群展開。 首先，使用MarkerCluster方法創建一個集群，可以在lib庫folium.plugins下找到它 12from folium.plugins import MarkerClustermarker_cluster = MarkerCluster().add_to(m_1) 而不是通過.add_to（map）將所有標記添加到我們的地圖中 我們將通過.add_to(集群名稱)將它們添加到集群 在我們的例子中是.add_to（m_1） 如下所示，當您放大和縮小地圖時，所有群集將自動展開並摺疊 用海廢等級作顏色區分 12345678910111213141516171819202122232425for index, row in df_train.iterrows():if row['LEVEL'] ==10 :information = 'County:'+str(row['County'])+'&lt;br&gt;'+'Location:'+str(row['Location'])+'&lt;br&gt;'+'Season:'+str(row['Season'])+'&lt;br&gt;'+'LEVEL:'+str(row['LEVEL'])folium.Marker(location=[row['Lat'],row['Lon']],icon=folium.Icon(color='red'),popup=information).add_to(marker_cluster)if 9&gt;= row['LEVEL'] &gt;=7 :information = 'County:'+str(row['County'])+'&lt;br&gt;'+'Location:'+str(row['Location'])+'&lt;br&gt;'+'Season:'+str(row['Season'])+'&lt;br&gt;'+'LEVEL:'+str(row['LEVEL'])folium.Marker(location=[row['Lat'],row['Lon']],icon=folium.Icon(color='orange'),popup=information).add_to(marker_cluster)if 6&gt;= row['LEVEL'] &gt;=4 :information = 'County:'+str(row['County'])+'&lt;br&gt;'+'Location:'+str(row['Location'])+'&lt;br&gt;'+'Season:'+str(row['Season'])+'&lt;br&gt;'+'LEVEL:'+str(row['LEVEL'])folium.Marker(location=[row['Lat'],row['Lon']],icon=folium.Icon(color='darkgreen'),popup=information).add_to(marker_cluster)if 3&gt;= row['LEVEL'] &gt;=1 :information = 'County:'+str(row['County'])+'&lt;br&gt;'+'Location:'+str(row['Location'])+'&lt;br&gt;'+'Season:'+str(row['Season'])+'&lt;br&gt;'+'LEVEL:'+str(row['LEVEL'])folium.Marker(location=[row['Lat'],row['Lon']],icon=folium.Icon(color='green'),popup=information).add_to(marker_cluster) 匯入垃圾資料 12345df_sata = pd.read_csv('trash.csv')lat1 = list(df_sata[\"Latitude\"])longt1 = list(df_sata[\"Longitude\"])co1 = list(df_sata[\"縣市\"])loc1 = list(df_sata[\"名稱\"]) 圖層管理(FeatureGroup) 1234567fg1 = folium.FeatureGroup(name=\"My trash\")for lt, ln, name1, name2 in zip(lat1, longt1, co1, loc1):fg1.add_child(folium.Marker(location=[lt, ln], popup=str(name1.replace(\"'\", \"\").replace('\"', \"\"))+(name2.replace(\"'\", \"\").replace('\"', \"\")), icon=folium.Icon(color='red')))m_1.add_child(fg1)m_1.add_child(folium.LayerControl()) #","link":"/2020/05/11/folium/"}],"tags":[{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"python","slug":"python","link":"/tags/python/"}],"categories":[{"name":"hexo","slug":"hexo","link":"/categories/hexo/"},{"name":"python","slug":"python","link":"/categories/python/"},{"name":"tag_replace_process","slug":"python/tag-replace-process","link":"/categories/python/tag-replace-process/"}]}